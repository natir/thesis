\documentclass[main.tex]{subfiles}

\begin{document}

\chapter{Preassembly} \label{chapter:preassembly}

Two key aspects in long-read genome assembly are 1) the detection of overlaps between reads and 2) dealing with errors in reads. Computing overlaps is done prior to assembly can thus be considered as a preassembly task, even if some assembly pipelines compute overlaps several times. Computing overlaps is a hard task, even harder with high error rate reads. A number of tools have been designed in the last decade, with their own definition of what is an 'good' overlap. The section \ref{sec:preasm:ovl} gives a short overview of algorithmic ideas on which overlappers are designed. The next section (\ref{sec:preasm:blog_post}) discusses about comparison of overlaps found by state-of-the-art overlappers for long read data. 

\bigskip

After sequencing a usual task is to clean the set of reads, e.g.
\begin{itemize}
	\item remove too short reads (less than 500~bp, 1000~bp or even 2000~bp)
	\item find and remove the sequencing adaptors (that is a short sequence added before DNA fragment, this short sequence is required for some biochemical consideration, but they can create trouble in assembly)
\end{itemize}
or perform some operations to improve the quality of reads, e.g.
\begin{itemize}
	\item found highly erroneous regions of reads and replace them by more correct one, this operation is called \emph{scrubbing}
	\item correct reads using information from other sequencing technology (this is called hybrid correction) or with same technology, this operation is called \emph{correction} 
\end{itemize}
Cleaning preprocessing intends to improve the quality of the assembly or to help the task of assembly (e.g. by reducing the number of false overlaps). 
As overlapping tools didn't know what the user will do with the computed set of overlaps, all information is reported (it's a good point). But one has to remember that the number of overlaps for a common sequencing experiment is very large, storing them may require more than terabyte for some large dataset. In section \ref{sec:preasm:intro_fpa} we introduce in more details this trouble and the solution we have design. \jsv{paragraphe a retravailler}

Correction and scrubbing seeks to perform the same target: reduce the error rate of reads. Scrubbing works on large region (around ten or hundred bases) while correction works at the level of one base. This difference of scale implies different requirements in terms of computation time and memory usage. Section \ref{sec:preasm:yacrd} discusses the interest of scrubbing towards correction.

Our work on overlap selection and on scrubbing tools was merged in a paper presented in section \ref{section:preassembly:paper}.

\section{Overlaps and their impact on assembly}

\subsection{How to find similar regions between sequence} \label{sec:preasm:ovl}

As we defined in the introduction, when two sequences share a common substring, we say that they overlap or that one of them maps on the other see \ref{intro:fig:overlap:perfect}. It is possible for sequences to share a common substring just by chance (because of the 4-letter alphabet) but the probability of this event decreases when the length of the common substring increases. Intuitively, this probability gets smaller as common substring gets longer. If the reads does not contain sequencing errors, the only criteria to evaluate whether a common substring is "true" or not could be the length of this substring. However, the number of errors in the sequence of readings breaks this paradigm and forces us to integrate the errors when assessing the quality of an overlap. Figure \ref{intro:fig:overlap:erroneous} show an overlap with two mismatch. There are two base pairs that do not match between the two sequences - knowing if this overlap is "true" or not isn't obvious.


\begin{figure}[ht]
    \centering
    \subfloat[ht][$R_1$ shares 7 bases at its end with the beginning of $R_2$, without any error]{
        \subfile{introduction/tikz/perfect_overlap.tex}
        \label{intro:fig:overlap:perfect}
    }
    \subfloat[ht][$R_1$ shares 5 bases at its end with $R_3$, with one substitution and one deletion]{
        \subfile{introduction/tikz/erroneous_overlap.tex}
        \label{intro:fig:overlap:erroneous}
    }
    \caption{When reads don't contain error, overlaps look like (a), but sequencing technologies make errors and the overlap present in (b) can be a true overlap.}
    \label{intro:fig:overlap}
\end{figure}

In this document we distinguish two tasks in similarity search between two sequences:
\begin{itemize}
    \item mapping: one tries to find the position of a read in a larger sequence (e.g. comparing different datasets, experiments from different sequencing generations, or between the reads and an assembly, against a reference genome)
    \item overlapping: one tries to find which reads share a common substring with other reads (e.g. finding common substrings in the same dataset) 
\end{itemize}
Even if mapping and overlapping can be seen as different tasks, one could observe that the same tools, and underlying algorithmic, can be used to solve both tasks.


\paragraph{The seed-and-extend strategy.} 
Search of similarity between two or more DNA sequences has many links to plain text search.
Seed-and-extend is an approach used by many tools to find similar sequences between a target (e.g. a reference genome) and a query (e.g. a read). The idea is to find a high similar subsequence (often exact), namely the seed (or anchor), and then to extend this seed to have a larger common subsequence. Tools that implement this approach usually create an index of the target. This index need to answer to a simple question: is a given subsequence exist in target and at which position. Each query is processed and its substrings are searched in the index. This gives a set of seeds that can be extended through alignment techniques such as dynamic programming. If the alignment score reaches a given threshold, a hit is reported.

Many tools for mapping and overlapping use seed-and-extend strategy. The most popular is \toolsname{Blast} \cite{blast_one, blast_two}. Specific tools dedicated to sequencing are \toolsname{BWA} \cite{bwa_mem} or \toolsname{blasr} \cite{blasr}. Implementation details of indexes, size and number of anchors change between tools. For example \toolsname{BWA} or \toolsname{blasr} use a FM-index \cite{fm-index} to perform anchor search.

\paragraph{The seed-only strategy.}

With NGS technology development more and more data had to be processed and the seed-and-extend strategy was replaced by a seed-only strategy. Indeed, the extension step is still very time-consuming. With the seed-and-extend strategy, an overlap is scored by its length and the number of errors in the alignment. With the seed-only strategy we don't have an alignment. The overlap is thus scored using the number of seeds and their positions. 

This strategy was used in \toolsname{SGA} \cite{SGA} assembly tools, during overlapping step \toolsname{SGA} search exact overlap between low error read, by search a substring at end of read in a FM-index. 

Specificity of long-reads (longer reads, high error rate) has relaunched this research field. \citeauthor{ovl_bench} produce an interesting review about some of third-generation overlap search in \cite{ovl_bench}, discussed in next section. 
We can cite \toolsname{Hisea} \cite{hisea}, \toolsname{Daligner} \cite{daligner}, \mhap \cite{canu} and \minimap \cite{minimap, minimap2} as overlapping tools they use this strategy to found overlap between thrid generation overlap. We will give some details on \mhap and \minimap in section \ref{chapter:sota}.

For third generation reads, the length of the reads and the large number of errors make the choice of algorithm parameters even more complicated, particularly concerning how we choose the seed and length of seeds. But by removing the extend step the computation time was reduce and help to manage the high error rate of thrid generation reads.

\paragraph{On the importance of overlaps.}

As overlaps are the basic components to reconstruct the original sequence, a missing overlap may lead to a wrong assembly (entire pieces of the genome inverted) or to a high number of contigs. In \cite{ovl_bench}, \citeauthor{ovl_bench} compare the state of the art third generation sequencing read overlappers on simulated datasets and on real datasets. A drop in the accuracy and recall of these algorithms can be observed between real and simulated data \ref{preassembly:tab:ovl_result}.
\begin{table}[ht]
    \centering
    \begin{tabular}{l|rr|rr}
                & \multicolumn{2}{c}{Pacbio}                & \multicolumn{2}{c}{Nanopore}              \\ 
                & Simulated           & Real                & Simulated         & Real                  \\ \hline
    Sensibility & 88.9$^m$ - 92.4$^d$ & 59.6$^m$ - 83.8$^d$ & 90.4$^g$ - 95.2$^b$ & 88.9$^b$ - 92.9$^d$ \\
    Precision   & 81.9$^b$ - 96.5$^g$ & 79.8$^h$ - 96.5$^b$ & 75.1$^b$ - 99$^m$   & 73$^b$ - 95.4$^m$   \\
    \end{tabular}
    \caption{\textsuperscript{m}\toolsname{Minimap}, \textsuperscript{d}\toolsname{Daligner}, \textsuperscript{g}\toolsname{GraphMap}, \textsuperscript{b}\toolsname{BLASR}, \textsuperscript{h}\mhap}
    \label{preassembly:tab:ovl_result}
\end{table}

In a blog post "State-of-the-art long reads overlappers comparison" \footnote{\url{https://blog.pierre.marijon.fr/long-reads-overlapper-compare/}} we take the same data as \cite{ovl_bench} but we didn't care if the overlappers found 'right' or 'wrong' overlaps. Instead we searched for comparing overlaps sets to decide whether or not overlappers compute the same overlaps. There were differences large enough to justify the idea of creating a kind of 'reconciliation' tool that merge information from several overlapper. This blog post was presented at the poster session of JOBIM (\textit{Journée Ouverte de Bioinformatique \& Mathematique}) 2018.

\subfile{paper/blog_post.tex}

\section{Improving assembly by filtering out overlaps and scrubbing}

\subsection{Improve genome assembly efficiency by reducing the quantity of information} \label{sec:preasm:intro_fpa}

Error in third generation reads make it more difficult to found overlaps between reads. Current techniques attempt to optimize results on real data \cite{ovl_bench}.
Actually, a key observation is that within the overlaps found by state-of-the-art tools, not all of them are useful to downstream analysis. For example \miniasm keeps only end-to-end overlaps, and \canu keeps only the two longest end-to-end overlaps for each read (see \ref{chapter:sota} for more details).

Figure \ref{intro:fig:length_overlap_histogram} shows a histogram of overlap lengths found by \minimap on \textit{E. coli} Nanopore dataset (acession number SRR8494940): 33 \% of overlaps are shorter than 2000 bases. By default \miniasm ignores overlaps shorter than 2000 bases that is if we run a basic \miniasm pipeline, 33\% of the overlap will not be used but they are written on the disk.  
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{introduction/images/overlap_length.pdf}
    \caption{Histogram of overlap lengths found by \minimap, the black line represents the \miniasm overlap length threshold. The fasta file weight 3.1 Go, complete PAF file generate by \minimap weight 5.5 Go, without overlap lower than 2000 bases the weight is reduced to 3.7 Go.}
    \label{intro:fig:length_overlap_histogram}
\end{figure}
There is definitively room for improvement. Can we filter overlapping information with positive (or at least no negative) impact on assembly results ? One may hope to at least decrease the disk space and may be to increase the speed of assembly.

In section \ref{section:preassembly:paper} we present \fpa (for Filter Pairwise Alignment), our solution to solve filter out useless overlaps. An overlaper output can be piped directly to \fpa. \fpa can apply several filters based on length of read, length of overlap, type of overlap, read name. Some simple \fpa filters reduce the computation time of assembly without effect (or a small positive effect) on assembly.


\subsection{Read scrubbing: an alternative of read correction} \label{sec:preasm:intro_yacrd}

Assembly tools are based on reads. If your reads are bad, your assembly will be bad. To continue on the analogy given in the introduction, you probably cannot reconstruct a book if crazy monks gave to you only fragments with half of the letters being erroneous. Correction of reads, with a mix of sequencing technologies (or with a single technology), can help you to get better reads. But actually, correction tools have an important cost in term of computation time and memory usage. Moreover it's hard to differentiate natural mutations (e.g. real SNPs) to sequencing errors, and sometimes interesting mutations are consider as errors and are corrected (thus removed).

Correction was per-processing step to found and remove error in reads, this step was particularly important for long-reads data because her error rate was important and can lead to more error and misassembly in assembly. Roughly correction use overlap information to pick other reads share same sequence of a read need to be correct and use all information present sequence to build a consensus, we can cite tools like \toolsname{Mecat}\cite{MECAT}, \toolsname{CONSENT}\cite{CONSENT}. A similar task call polishing, was run after assembly, read are mapped against contig and contig sequence was correct with reads information we can site \toolsname{Racon}\cite{racon} and \toolsname{CONSENT}.

More than read contains error more correction required many reads, but the sequencing depth is not homogeneous and if for a given region this depth is not sufficient for the corrector, it will be less effective but it could still reduce the sequencing depth by eliminating reads or part of reads. To solve this problem it is necessary either to work without correction or to return to the raw reads to find the lost connection.

At the best of our knowledge the only one reads correctors they try to keept the hetrozygotie during correction is falcon \cite{falcon}, the other didn't try to keep this information. Or heterozygotie are very use full to understand genetic diversity in population or some genetic disease.
Moreover if you genome contain some almost repetion (two instance of same text with some mutation), the correction maybe can't distinguish the mutation between this two instance to sequencing error and correct the two instance of the almost repetition to the same sequence, so correction can create a repetition that cannot be resolved where there were we have two solvable almost repetitions.

Correction of reads before assembly can generate some trouble in assembly by remove some important read. But long-reads still contains very low quality region \cite{blog_post_error_repartition} this region can lead to a fragmented assembly \cite{long_read_assembler_comparison}. An alternative to preassembly correction can be scrubbing, remove only very low quality region and keep all other information.

To found and remove this very low quality region and read we create \yacrd (for Yet Another Chimeric Read Detector), \yacrd use self overlapping information to compute a coverage curve and identify region with low coverage. We suppose this low coverage region is region with low quality, read section \ref{section:preassembly:paper} for more details on this tools.


Our paper "\yacrd and \fpa: upstream tools for long-read genome assembly" presents two tools, \yacrd , and \fpa. \yacrd focuses on the detection and elimination of very poor quality regions. \fpa focuses on filtering 'useless' overlaps.

\subfile{paper/yacrd_fpa.tex}

\section{Chapter conclusion}

In this chapter we have proposed a benchmark of overlappers, a filtering tool for these overlap and a scrubbing tool.

The blog post on overlapping tools comparison demonstrates that they do not found same overlaps. We should be able to improve the quality of the overlaps we found between reads by combining results from several tools. This is the idea of an overlap consensus generator. But in the blog post we consider if two overlapping tools found a overlap between same reads they found the same overlap. But in a case of two reads \texttt{A} and \texttt{B}, it's possible:
\begin{itemize}
    \item the first overlapping tools found the end of read \texttt{A} overlap the begin of read \texttt{B}
    \item the second overlapping tools found the end of read \texttt{B} overlap the begin of read \texttt{A}
    \item the third overlapping tools found the reads \texttt{A} and \texttt{B} share an internal match
\end{itemize}

This list can be continued indefinitely. If we want build a overlaps consensus generator we need found a method, to say this two overlap found by two different overlapping tools, concern the same region of read \texttt{A} and the same region of read \texttt{B}, we can increase our confidence in this overlap is a \textit{true} overlap and it's is between this region of \texttt{A} and this region of read \texttt{B}. Or all overlapping tools found an overlap between read \texttt{C} and \texttt{D} but all this overlap concern different region of \texttt{C} and \texttt{D}, we can say they are probably no overlap between \texttt{C} and \texttt{D}.
This work was made in the context of a PFE (\textit{Projet de Fin d'Étude} End of Study Projects) by Yann Grabe. He create a tool that will build a consensus of several overlap files, by founding overlap between overlap and compute a confident score on each overlap by evaluate the number of overllaping tools found the same overlap.

For the moment this tool is only a prototype and would still require a lot of work before it can be finalized. 

%\onlyinsubfile{
%\bibliographystyle{plainnat}
%\bibliography{main}
%\addcontentsline{toc}{chapter}{Bibliography}
%}

\end{document}